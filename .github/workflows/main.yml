name: pt.csust_crawler

on:
  workflow_dispatch:
  # schedule:
  # - cron: '30 */3 * * *'

jobs:
  main:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3
      with:
        fetch-depth: 0
        token: ${{ secrets.WORKFLOW_TOKEN }}
    - run: git checkout instance

    - uses: actions/setup-python@v3
    
    - name: Set env
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Run crawler
      run: |
        echo "## 运行时间：" > info.bak.log
        echo `date` >> info.bak.log
        echo "## 运行情况：" >> info.bak.log
        python main.py >> info.bak.log
        echo -e "=========================\n\n" >> info.bak.log
    - name: Update logs
      run: |
        source update_log.sh
    - name: Commit .env #上传新的refresh_token到仓库
      run: |
        git config --global user.email "your_email"
        git config --global user.name "your_nickname"
        git add .
        git commit --amend --no-edit
    - name: Push instance
      uses: ad-m/github-push-action@master
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        branch: instance
        force: true
    - name: Adjust running frequency
      run: |
        git checkout master > /dev/null 2>&1
        source push.sh
    - name: Push master
      uses: ad-m/github-push-action@master
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        branch: master